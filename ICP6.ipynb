{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1qgCxmemDYsRAjbVLNWGKPUenz8BGlIz4","timestamp":1729725154598}],"gpuType":"T4","authorship_tag":"ABX9TyMAo67Br/v84GWwwl7lQIgn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Load the MNIST dataset\n","(x_train, _), (x_test, _) = mnist.load_data()\n","\n","# Normalize pixel values to the range [0, 1]\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","# Flatten the images for the autoencoder\n","x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n","x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n","\n","# Define the dimensions of the input and the encoded representation\n","input_dim = x_train.shape[1]\n","encoding_dim = 16  # Compress to 16 features\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Define the encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","# Adding a layer\n","encoded_layer = Dense(encoding_dim, activation='relu')(encoded)\n","\n","# Define the decoder, use encoded_layer as input instead of encoded1\n","# Adding a layer\n","decoded_layer = Dense(encoding_dim, activation='relu')(encoded_layer) # Use encoded_layer here\n","# Define the decoder\n","decoded = Dense(input_dim, activation='sigmoid')(decoded_layer) # Use decoded_layer here\n","\n","\n","# Combine the encoder and decoder into an autoencoder model\n","autoencoder = Model(input_layer, decoded)\n","\n","# Define EarlyStopping\n","early_stopping = EarlyStopping(monitor='val_loss',\n","                               patience=5,  # Number of epochs with no improvement after which training will be stopped\n","                               restore_best_weights=True)  # Restores model to best weights with the lowest validation loss\n","\n","# Compile the autoencoder model\n","autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","# Train the autoencoder\n","autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n","                epochs=100,  # Set a high number of epochs\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(x_test, x_test),\n","                callbacks=[early_stopping])  # Add the early stopping callback"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aZPcnTCxgkbB","executionInfo":{"status":"ok","timestamp":1729722799289,"user_tz":300,"elapsed":64128,"user":{"displayName":"Venkata Nitish Bayarapuneni","userId":"02491724517830937665"}},"outputId":"7f87f79e-670c-4616-dfd5-1dc80ead030e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.4325 - val_loss: 0.2316\n","Epoch 2/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2238 - val_loss: 0.2064\n","Epoch 3/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2029 - val_loss: 0.1836\n","Epoch 4/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1815 - val_loss: 0.1728\n","Epoch 5/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1721 - val_loss: 0.1638\n","Epoch 6/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1633 - val_loss: 0.1571\n","Epoch 7/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1580 - val_loss: 0.1552\n","Epoch 8/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1556 - val_loss: 0.1520\n","Epoch 9/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1532 - val_loss: 0.1500\n","Epoch 10/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1510 - val_loss: 0.1488\n","Epoch 11/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1500 - val_loss: 0.1482\n","Epoch 12/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1494 - val_loss: 0.1478\n","Epoch 13/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1488 - val_loss: 0.1473\n","Epoch 14/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1484 - val_loss: 0.1469\n","Epoch 15/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1479 - val_loss: 0.1467\n","Epoch 16/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1477 - val_loss: 0.1462\n","Epoch 17/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1475 - val_loss: 0.1462\n","Epoch 18/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1473 - val_loss: 0.1454\n","Epoch 19/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1466 - val_loss: 0.1449\n","Epoch 20/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1462 - val_loss: 0.1442\n","Epoch 21/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1457 - val_loss: 0.1437\n","Epoch 22/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1449 - val_loss: 0.1428\n","Epoch 23/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1440 - val_loss: 0.1422\n","Epoch 24/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1431 - val_loss: 0.1411\n","Epoch 25/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1425 - val_loss: 0.1406\n","Epoch 26/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1422 - val_loss: 0.1399\n","Epoch 27/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1413 - val_loss: 0.1396\n","Epoch 28/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1411 - val_loss: 0.1392\n","Epoch 29/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1406 - val_loss: 0.1388\n","Epoch 30/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1399 - val_loss: 0.1385\n","Epoch 31/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1400 - val_loss: 0.1382\n","Epoch 32/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1395 - val_loss: 0.1382\n","Epoch 33/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1396 - val_loss: 0.1379\n","Epoch 34/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1396 - val_loss: 0.1378\n","Epoch 35/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1394 - val_loss: 0.1376\n","Epoch 36/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1390 - val_loss: 0.1375\n","Epoch 37/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1390 - val_loss: 0.1375\n","Epoch 38/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1393 - val_loss: 0.1373\n","Epoch 39/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1383 - val_loss: 0.1370\n","Epoch 40/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1387 - val_loss: 0.1369\n","Epoch 41/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1381 - val_loss: 0.1368\n","Epoch 42/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1382 - val_loss: 0.1368\n","Epoch 43/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1381 - val_loss: 0.1364\n","Epoch 44/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1378 - val_loss: 0.1362\n","Epoch 45/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1375 - val_loss: 0.1360\n","Epoch 46/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1377 - val_loss: 0.1359\n","Epoch 47/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1374 - val_loss: 0.1358\n","Epoch 48/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1371 - val_loss: 0.1355\n","Epoch 49/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1371 - val_loss: 0.1355\n","Epoch 50/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1372 - val_loss: 0.1355\n","Epoch 51/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1367 - val_loss: 0.1353\n","Epoch 52/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1365 - val_loss: 0.1352\n","Epoch 53/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1365 - val_loss: 0.1351\n","Epoch 54/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1368 - val_loss: 0.1355\n","Epoch 55/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1365 - val_loss: 0.1350\n","Epoch 56/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1365 - val_loss: 0.1349\n","Epoch 57/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1364 - val_loss: 0.1350\n","Epoch 58/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1363 - val_loss: 0.1349\n","Epoch 59/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1362 - val_loss: 0.1349\n","Epoch 60/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1364 - val_loss: 0.1348\n","Epoch 61/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1364 - val_loss: 0.1348\n","Epoch 62/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1363 - val_loss: 0.1347\n","Epoch 63/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1364 - val_loss: 0.1347\n","Epoch 64/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1361 - val_loss: 0.1348\n","Epoch 65/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1363 - val_loss: 0.1348\n","Epoch 66/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1362 - val_loss: 0.1347\n","Epoch 67/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1361 - val_loss: 0.1347\n","Epoch 68/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1364 - val_loss: 0.1346\n","Epoch 69/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1362 - val_loss: 0.1347\n","Epoch 70/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1363 - val_loss: 0.1346\n","Epoch 71/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1359 - val_loss: 0.1346\n","Epoch 72/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1362 - val_loss: 0.1348\n","Epoch 73/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1363 - val_loss: 0.1346\n","Epoch 74/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1359 - val_loss: 0.1345\n","Epoch 75/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1359 - val_loss: 0.1345\n","Epoch 76/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1360 - val_loss: 0.1344\n","Epoch 77/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1359 - val_loss: 0.1345\n","Epoch 78/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1361 - val_loss: 0.1346\n","Epoch 79/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1360 - val_loss: 0.1342\n","Epoch 80/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1359 - val_loss: 0.1343\n","Epoch 81/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1356 - val_loss: 0.1343\n","Epoch 82/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1359 - val_loss: 0.1344\n","Epoch 83/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1356 - val_loss: 0.1343\n","Epoch 84/100\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1355 - val_loss: 0.1342\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7ed8ce567f70>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.callbacks import TerminateOnNaN\n","\n","# Define the TerminateOnNaN callback\n","terminate_on_nan = TerminateOnNaN()\n","\n","# Load the MNIST dataset\n","(x_train, _), (x_test, _) = mnist.load_data()\n","\n","# Normalize pixel values to the range [0, 1]\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","# Flatten the images for the autoencoder\n","x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n","x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n","\n","# Define the dimensions of the input and the encoded representation\n","input_dim = x_train.shape[1]\n","encoding_dim = 16  # Compress to 16 features\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Define the encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","# Adding a layer\n","encoded_layer = Dense(encoding_dim, activation='relu')(encoded)\n","\n","# Adding a layer, use encoded_layer as input instead of encoded1\n","decoded_layer = Dense(encoding_dim, activation='relu')(encoded_layer) # Use encoded_layer here\n","# Define the decoder, use decoded_layer as input instead of decoded1\n","decoded = Dense(input_dim, activation='sigmoid')(decoded_layer) # Use decoded_layer here\n","\n","# Combine the encoder and decoder into an autoencoder model\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the autoencoder model\n","autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","# Train the autoencoder\n","# Assuming x_train and x_test are your training and validation datasets\n","autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n","                epochs=30,  # Set the number of epochs\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(x_test, x_test),\n","                callbacks=[terminate_on_nan])  # Add the TerminateOn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oFBHU4zHhcaS","executionInfo":{"status":"ok","timestamp":1729722990929,"user_tz":300,"elapsed":27068,"user":{"displayName":"Venkata Nitish Bayarapuneni","userId":"02491724517830937665"}},"outputId":"d4364d0f-ba81-4a19-cfe3-1059fe841269"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.4180 - val_loss: 0.2390\n","Epoch 2/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2308 - val_loss: 0.2051\n","Epoch 3/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1991 - val_loss: 0.1788\n","Epoch 4/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1779 - val_loss: 0.1705\n","Epoch 5/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1701 - val_loss: 0.1652\n","Epoch 6/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1644 - val_loss: 0.1606\n","Epoch 7/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1604 - val_loss: 0.1574\n","Epoch 8/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1578 - val_loss: 0.1541\n","Epoch 9/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1547 - val_loss: 0.1502\n","Epoch 10/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1512 - val_loss: 0.1483\n","Epoch 11/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1494 - val_loss: 0.1468\n","Epoch 12/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1471 - val_loss: 0.1449\n","Epoch 13/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1454 - val_loss: 0.1431\n","Epoch 14/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1443 - val_loss: 0.1423\n","Epoch 15/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1434 - val_loss: 0.1414\n","Epoch 16/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1428 - val_loss: 0.1410\n","Epoch 17/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1422 - val_loss: 0.1405\n","Epoch 18/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1419 - val_loss: 0.1402\n","Epoch 19/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1412 - val_loss: 0.1397\n","Epoch 20/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1410 - val_loss: 0.1396\n","Epoch 21/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1407 - val_loss: 0.1391\n","Epoch 22/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1405 - val_loss: 0.1388\n","Epoch 23/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1398 - val_loss: 0.1384\n","Epoch 24/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1396 - val_loss: 0.1379\n","Epoch 25/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1392 - val_loss: 0.1373\n","Epoch 26/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1389 - val_loss: 0.1369\n","Epoch 27/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1382 - val_loss: 0.1367\n","Epoch 28/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1380 - val_loss: 0.1362\n","Epoch 29/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1380 - val_loss: 0.1360\n","Epoch 30/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1377 - val_loss: 0.1358\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7ed8a0178b20>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# Define the ModelCheckpoint callback\n","checkpoint = ModelCheckpoint(filepath='autoencoder_best.keras',  # File path to save the model\n","                             monitor='val_loss',  # Metric to monitor\n","                             save_best_only=True,  # Save only the best model (based on the monitored metric)\n","                             mode='min',  # Minimize the monitored metric (e.g., validation loss)\n","                             save_weights_only=False,  # Save the entire model (set to True to save only weights)\n","                             verbose=1)  # Print a message when saving the model\n","\n","\n","# Load the MNIST dataset\n","(x_train, _), (x_test, _) = mnist.load_data()\n","\n","# Normalize pixel values to the range [0, 1]\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","# Flatten the images for the autoencoder\n","x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n","x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n","\n","# Define the dimensions of the input and the encoded representation\n","input_dim = x_train.shape[1]\n","encoding_dim = 16  # Compress to 16 features\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Define the encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","# Adding a layer\n","encoded_layer = Dense(encoding_dim, activation='relu')(encoded)\n","\n","# Adding a layer, use encoded_layer as input instead of encoded1\n","decoded_layer = Dense(encoding_dim, activation='relu')(encoded_layer)  # Use encoded_layer here\n","# Define the decoder, use decoded_layer as input instead of decoded1\n","decoded = Dense(input_dim, activation='sigmoid')(decoded_layer)  # Use decoded_layer here\n","\n","# Combine the encoder and decoder into an autoencoder model\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the autoencoder model\n","autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","# Train the autoencoder\n","# Assuming x_train and x_test are your training and validation datasets\n","autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n","                epochs=30,  # Number of epochs\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(x_test, x_test),  # Validation data\n","                callbacks=[checkpoint])  # Add the ModelCheckpoint callback"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_KHuWy8ibHn","executionInfo":{"status":"ok","timestamp":1729723254502,"user_tz":300,"elapsed":32115,"user":{"displayName":"Venkata Nitish Bayarapuneni","userId":"02491724517830937665"}},"outputId":"3aa83204-ca4a-4a7c-8b9d-e4f4e8e9b4a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4228\n","Epoch 1: val_loss improved from inf to 0.24127, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.4223 - val_loss: 0.2413\n","Epoch 2/30\n","\u001b[1m212/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2357\n","Epoch 2: val_loss improved from 0.24127 to 0.21225, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2349 - val_loss: 0.2122\n","Epoch 3/30\n","\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2091\n","Epoch 3: val_loss improved from 0.21225 to 0.19490, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2090 - val_loss: 0.1949\n","Epoch 4/30\n","\u001b[1m217/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1914\n","Epoch 4: val_loss improved from 0.19490 to 0.17850, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1910 - val_loss: 0.1785\n","Epoch 5/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1787\n","Epoch 5: val_loss improved from 0.17850 to 0.17324, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1787 - val_loss: 0.1732\n","Epoch 6/30\n","\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1731\n","Epoch 6: val_loss improved from 0.17324 to 0.16724, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1731 - val_loss: 0.1672\n","Epoch 7/30\n","\u001b[1m218/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1679\n","Epoch 7: val_loss improved from 0.16724 to 0.16325, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1678 - val_loss: 0.1632\n","Epoch 8/30\n","\u001b[1m208/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1634\n","Epoch 8: val_loss improved from 0.16325 to 0.15985, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1634 - val_loss: 0.1598\n","Epoch 9/30\n","\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1607\n","Epoch 9: val_loss improved from 0.15985 to 0.15754, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1607 - val_loss: 0.1575\n","Epoch 10/30\n","\u001b[1m227/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1585\n","Epoch 10: val_loss improved from 0.15754 to 0.15618, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1585 - val_loss: 0.1562\n","Epoch 11/30\n","\u001b[1m224/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1570\n","Epoch 11: val_loss improved from 0.15618 to 0.15519, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1570 - val_loss: 0.1552\n","Epoch 12/30\n","\u001b[1m226/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1563\n","Epoch 12: val_loss improved from 0.15519 to 0.15439, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1563 - val_loss: 0.1544\n","Epoch 13/30\n","\u001b[1m221/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1554\n","Epoch 13: val_loss improved from 0.15439 to 0.15340, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1554 - val_loss: 0.1534\n","Epoch 14/30\n","\u001b[1m228/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1547\n","Epoch 14: val_loss improved from 0.15340 to 0.15246, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1547 - val_loss: 0.1525\n","Epoch 15/30\n","\u001b[1m227/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1535\n","Epoch 15: val_loss improved from 0.15246 to 0.15105, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1534 - val_loss: 0.1511\n","Epoch 16/30\n","\u001b[1m224/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1520\n","Epoch 16: val_loss improved from 0.15105 to 0.14974, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1520 - val_loss: 0.1497\n","Epoch 17/30\n","\u001b[1m221/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1507\n","Epoch 17: val_loss improved from 0.14974 to 0.14843, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1506 - val_loss: 0.1484\n","Epoch 18/30\n","\u001b[1m222/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1496\n","Epoch 18: val_loss improved from 0.14843 to 0.14767, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1496 - val_loss: 0.1477\n","Epoch 19/30\n","\u001b[1m225/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1487\n","Epoch 19: val_loss improved from 0.14767 to 0.14692, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1487 - val_loss: 0.1469\n","Epoch 20/30\n","\u001b[1m228/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1480\n","Epoch 20: val_loss improved from 0.14692 to 0.14643, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1480 - val_loss: 0.1464\n","Epoch 21/30\n","\u001b[1m219/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1476\n","Epoch 21: val_loss improved from 0.14643 to 0.14607, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1476 - val_loss: 0.1461\n","Epoch 22/30\n","\u001b[1m212/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1475\n","Epoch 22: val_loss improved from 0.14607 to 0.14565, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1474 - val_loss: 0.1456\n","Epoch 23/30\n","\u001b[1m223/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1472\n","Epoch 23: val_loss improved from 0.14565 to 0.14518, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1471 - val_loss: 0.1452\n","Epoch 24/30\n","\u001b[1m212/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1469\n","Epoch 24: val_loss improved from 0.14518 to 0.14472, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1468 - val_loss: 0.1447\n","Epoch 25/30\n","\u001b[1m224/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1463\n","Epoch 25: val_loss improved from 0.14472 to 0.14448, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1463 - val_loss: 0.1445\n","Epoch 26/30\n","\u001b[1m224/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1456\n","Epoch 26: val_loss improved from 0.14448 to 0.14408, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1456 - val_loss: 0.1441\n","Epoch 27/30\n","\u001b[1m234/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1456\n","Epoch 27: val_loss improved from 0.14408 to 0.14360, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1456 - val_loss: 0.1436\n","Epoch 28/30\n","\u001b[1m209/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1455\n","Epoch 28: val_loss improved from 0.14360 to 0.14340, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1455 - val_loss: 0.1434\n","Epoch 29/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1450\n","Epoch 29: val_loss improved from 0.14340 to 0.14313, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1450 - val_loss: 0.1431\n","Epoch 30/30\n","\u001b[1m227/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1448\n","Epoch 30: val_loss improved from 0.14313 to 0.14305, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1448 - val_loss: 0.1431\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7ed88a591a50>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","\n","# Define the ReduceLROnPlateau callback\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss',  # Metric to monitor\n","                              factor=0.5,  # Factor by which the learning rate will be reduced (new_lr = lr * factor)\n","                              patience=3,  # Number of epochs with no improvement after which learning rate will be reduced\n","                              min_lr=1e-6,  # Lower bound for the learning rate\n","                              verbose=1)  # Print message when the learning rate is reduced\n","\n","\n","# Load the MNIST dataset\n","(x_train, _), (x_test, _) = mnist.load_data()\n","\n","# Normalize pixel values to the range [0, 1]\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","# Flatten the images for the autoencoder\n","x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n","x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n","\n","# Define the dimensions of the input and the encoded representation\n","input_dim = x_train.shape[1]\n","encoding_dim = 16  # Compress to 16 features\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Define the encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","# Adding a layer\n","encoded_layer = Dense(encoding_dim, activation='relu')(encoded)\n","\n","# Adding a layer, use encoded_layer as input instead of encoded1\n","decoded_layer = Dense(encoding_dim, activation='relu')(encoded_layer) # Use encoded_layer here\n","# Define the decoder, use decoded_layer as input instead of decoded1\n","decoded = Dense(input_dim, activation='sigmoid')(decoded_layer) # Use decoded_layer here\n","\n","\n","# Combine the encoder and decoder into an autoencoder model\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the autoencoder model\n","autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","# Train the autoencoder\n","# Assuming x_train and x_test are your training and validation datasets\n","autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n","                epochs=30,  # Number of epochs\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(x_test, x_test),  # Validation data\n","                callbacks=[reduce_lr])  # Add the ReduceLROnPlateau callback"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PetB8KTojSQK","executionInfo":{"status":"ok","timestamp":1729723496079,"user_tz":300,"elapsed":37107,"user":{"displayName":"Venkata Nitish Bayarapuneni","userId":"02491724517830937665"}},"outputId":"dea38d00-62ba-43e3-c81a-04b4f385f367"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4497 - val_loss: 0.2481 - learning_rate: 0.0010\n","Epoch 2/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2384 - val_loss: 0.2096 - learning_rate: 0.0010\n","Epoch 3/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2064 - val_loss: 0.1901 - learning_rate: 0.0010\n","Epoch 4/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1891 - val_loss: 0.1828 - learning_rate: 0.0010\n","Epoch 5/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1832 - val_loss: 0.1784 - learning_rate: 0.0010\n","Epoch 6/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1788 - val_loss: 0.1743 - learning_rate: 0.0010\n","Epoch 7/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1746 - val_loss: 0.1694 - learning_rate: 0.0010\n","Epoch 8/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1695 - val_loss: 0.1656 - learning_rate: 0.0010\n","Epoch 9/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1661 - val_loss: 0.1630 - learning_rate: 0.0010\n","Epoch 10/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1636 - val_loss: 0.1604 - learning_rate: 0.0010\n","Epoch 11/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1614 - val_loss: 0.1587 - learning_rate: 0.0010\n","Epoch 12/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1595 - val_loss: 0.1577 - learning_rate: 0.0010\n","Epoch 13/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1588 - val_loss: 0.1569 - learning_rate: 0.0010\n","Epoch 14/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1579 - val_loss: 0.1563 - learning_rate: 0.0010\n","Epoch 15/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1574 - val_loss: 0.1557 - learning_rate: 0.0010\n","Epoch 16/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1569 - val_loss: 0.1552 - learning_rate: 0.0010\n","Epoch 17/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1562 - val_loss: 0.1546 - learning_rate: 0.0010\n","Epoch 18/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1558 - val_loss: 0.1541 - learning_rate: 0.0010\n","Epoch 19/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1555 - val_loss: 0.1539 - learning_rate: 0.0010\n","Epoch 20/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1548 - val_loss: 0.1535 - learning_rate: 0.0010\n","Epoch 21/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1548 - val_loss: 0.1532 - learning_rate: 0.0010\n","Epoch 22/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1546 - val_loss: 0.1529 - learning_rate: 0.0010\n","Epoch 23/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1543 - val_loss: 0.1526 - learning_rate: 0.0010\n","Epoch 24/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1538 - val_loss: 0.1525 - learning_rate: 0.0010\n","Epoch 25/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1536 - val_loss: 0.1521 - learning_rate: 0.0010\n","Epoch 26/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1536 - val_loss: 0.1520 - learning_rate: 0.0010\n","Epoch 27/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1539 - val_loss: 0.1518 - learning_rate: 0.0010\n","Epoch 28/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1530 - val_loss: 0.1517 - learning_rate: 0.0010\n","Epoch 29/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1528 - val_loss: 0.1514 - learning_rate: 0.0010\n","Epoch 30/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1527 - val_loss: 0.1514 - learning_rate: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7ed88a3a3580>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TerminateOnNaN, ReduceLROnPlateau\n","\n","# EarlyStopping callback to stop training if validation loss stops improving\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","# ModelCheckpoint callback to save the best model based on validation loss\n","checkpoint = ModelCheckpoint(filepath='autoencoder_best.keras', monitor='val_loss', save_best_only=True, verbose=1)\n","\n","# TerminateOnNaN callback to stop training if the loss becomes NaN\n","terminate_on_nan = TerminateOnNaN()\n","\n","# Define the ReduceLROnPlateau callback\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n","\n","# Load the MNIST dataset\n","(x_train, _), (x_test, _) = mnist.load_data()\n","\n","# Normalize pixel values to the range [0, 1]\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","# Flatten the images for the autoencoder\n","x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n","x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n","\n","# Define the dimensions of the input and the encoded representation\n","input_dim = x_train.shape[1]\n","encoding_dim = 16  # Compress to 16 features\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Define the encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","# Adding a layer\n","encoded_layer = Dense(encoding_dim, activation='relu')(encoded)\n","\n","# Adding a layer, use encoded_layer as input instead of encoded1\n","decoded_layer= Dense(encoding_dim, activation='relu')(encoded_layer)  # Fixed: Use encoded_layer here\n","# Define the decoder, use decoded_layer as input instead of decoded1\n","decoded = Dense(input_dim, activation='sigmoid')(decoded_layer)  # Fixed: Use decoded_layer here\n","\n","# Combine the encoder and decoder into an autoencoder model\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the autoencoder model\n","autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","# Training with multiple callbacks\n","autoencoder.fit(x_train, x_train,\n","                epochs=30,  # You can set a high number of epochs\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(x_test, x_test),\n","                callbacks=[reduce_lr, early_stopping, checkpoint, terminate_on_nan])  # Using multiple callbacks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyFtDFgske4u","executionInfo":{"status":"ok","timestamp":1729723796027,"user_tz":300,"elapsed":32222,"user":{"displayName":"Venkata Nitish Bayarapuneni","userId":"02491724517830937665"}},"outputId":"6c5b889e-6e4a-4bb5-9893-371689018432"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4245\n","Epoch 1: val_loss improved from inf to 0.23416, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4240 - val_loss: 0.2342 - learning_rate: 0.0010\n","Epoch 2/30\n","\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2260\n","Epoch 2: val_loss improved from 0.23416 to 0.20249, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2258 - val_loss: 0.2025 - learning_rate: 0.0010\n","Epoch 3/30\n","\u001b[1m225/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1984\n","Epoch 3: val_loss improved from 0.20249 to 0.18332, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1981 - val_loss: 0.1833 - learning_rate: 0.0010\n","Epoch 4/30\n","\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1825\n","Epoch 4: val_loss improved from 0.18332 to 0.17220, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1825 - val_loss: 0.1722 - learning_rate: 0.0010\n","Epoch 5/30\n","\u001b[1m222/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1715\n","Epoch 5: val_loss improved from 0.17220 to 0.16228, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1713 - val_loss: 0.1623 - learning_rate: 0.0010\n","Epoch 6/30\n","\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1627\n","Epoch 6: val_loss improved from 0.16228 to 0.15840, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1627 - val_loss: 0.1584 - learning_rate: 0.0010\n","Epoch 7/30\n","\u001b[1m210/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1586\n","Epoch 7: val_loss improved from 0.15840 to 0.15581, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1586 - val_loss: 0.1558 - learning_rate: 0.0010\n","Epoch 8/30\n","\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1569\n","Epoch 8: val_loss improved from 0.15581 to 0.15437, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1569 - val_loss: 0.1544 - learning_rate: 0.0010\n","Epoch 9/30\n","\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1550\n","Epoch 9: val_loss improved from 0.15437 to 0.15242, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1550 - val_loss: 0.1524 - learning_rate: 0.0010\n","Epoch 10/30\n","\u001b[1m234/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1528\n","Epoch 10: val_loss improved from 0.15242 to 0.15001, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1528 - val_loss: 0.1500 - learning_rate: 0.0010\n","Epoch 11/30\n","\u001b[1m223/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1507\n","Epoch 11: val_loss improved from 0.15001 to 0.14847, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1506 - val_loss: 0.1485 - learning_rate: 0.0010\n","Epoch 12/30\n","\u001b[1m221/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1499\n","Epoch 12: val_loss improved from 0.14847 to 0.14780, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1499 - val_loss: 0.1478 - learning_rate: 0.0010\n","Epoch 13/30\n","\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1485\n","Epoch 13: val_loss improved from 0.14780 to 0.14722, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1485 - val_loss: 0.1472 - learning_rate: 0.0010\n","Epoch 14/30\n","\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1484\n","Epoch 14: val_loss improved from 0.14722 to 0.14642, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1484 - val_loss: 0.1464 - learning_rate: 0.0010\n","Epoch 15/30\n","\u001b[1m216/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1476\n","Epoch 15: val_loss improved from 0.14642 to 0.14578, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1476 - val_loss: 0.1458 - learning_rate: 0.0010\n","Epoch 16/30\n","\u001b[1m221/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1473\n","Epoch 16: val_loss improved from 0.14578 to 0.14541, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1473 - val_loss: 0.1454 - learning_rate: 0.0010\n","Epoch 17/30\n","\u001b[1m228/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1469\n","Epoch 17: val_loss improved from 0.14541 to 0.14494, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1469 - val_loss: 0.1449 - learning_rate: 0.0010\n","Epoch 18/30\n","\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1465\n","Epoch 18: val_loss improved from 0.14494 to 0.14440, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1465 - val_loss: 0.1444 - learning_rate: 0.0010\n","Epoch 19/30\n","\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1461\n","Epoch 19: val_loss improved from 0.14440 to 0.14390, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1461 - val_loss: 0.1439 - learning_rate: 0.0010\n","Epoch 20/30\n","\u001b[1m225/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1457\n","Epoch 20: val_loss improved from 0.14390 to 0.14365, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1457 - val_loss: 0.1437 - learning_rate: 0.0010\n","Epoch 21/30\n","\u001b[1m228/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1446\n","Epoch 21: val_loss improved from 0.14365 to 0.14300, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1446 - val_loss: 0.1430 - learning_rate: 0.0010\n","Epoch 22/30\n","\u001b[1m226/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1443\n","Epoch 22: val_loss improved from 0.14300 to 0.14253, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1443 - val_loss: 0.1425 - learning_rate: 0.0010\n","Epoch 23/30\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1440\n","Epoch 23: val_loss improved from 0.14253 to 0.14191, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1440 - val_loss: 0.1419 - learning_rate: 0.0010\n","Epoch 24/30\n","\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1435\n","Epoch 24: val_loss improved from 0.14191 to 0.14126, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1435 - val_loss: 0.1413 - learning_rate: 0.0010\n","Epoch 25/30\n","\u001b[1m217/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1429\n","Epoch 25: val_loss improved from 0.14126 to 0.14068, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1429 - val_loss: 0.1407 - learning_rate: 0.0010\n","Epoch 26/30\n","\u001b[1m224/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1420\n","Epoch 26: val_loss improved from 0.14068 to 0.14040, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1420 - val_loss: 0.1404 - learning_rate: 0.0010\n","Epoch 27/30\n","\u001b[1m225/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1415\n","Epoch 27: val_loss improved from 0.14040 to 0.13958, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1415 - val_loss: 0.1396 - learning_rate: 0.0010\n","Epoch 28/30\n","\u001b[1m218/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1408\n","Epoch 28: val_loss improved from 0.13958 to 0.13924, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1408 - val_loss: 0.1392 - learning_rate: 0.0010\n","Epoch 29/30\n","\u001b[1m226/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1408\n","Epoch 29: val_loss improved from 0.13924 to 0.13874, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1408 - val_loss: 0.1387 - learning_rate: 0.0010\n","Epoch 30/30\n","\u001b[1m219/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1400\n","Epoch 30: val_loss improved from 0.13874 to 0.13834, saving model to autoencoder_best.keras\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1400 - val_loss: 0.1383 - learning_rate: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7ed88a0d5810>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","# Load the entire model\n","best_autoencoder = load_model('autoencoder_best.keras')\n","\n","# Let's look at the encoded representations\n","encoded_data = best_autoencoder.predict(x_test)\n","print(encoded_data)\n","print(encoded_data.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pp_4OC1bkrbK","executionInfo":{"status":"ok","timestamp":1729723823337,"user_tz":300,"elapsed":2884,"user":{"displayName":"Venkata Nitish Bayarapuneni","userId":"02491724517830937665"}},"outputId":"1fbb5d5b-9f2e-4334-b10c-f7e6bbd899ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n","[[1.75119294e-11 5.90835920e-13 3.34731982e-12 ... 9.35920265e-12\n","  1.14782457e-12 5.60907223e-13]\n"," [3.73498033e-09 4.47984192e-08 2.67801195e-08 ... 1.48025379e-08\n","  7.60447794e-09 1.10647704e-07]\n"," [9.43129949e-11 2.13933468e-10 9.09995745e-10 ... 3.27405131e-10\n","  3.95407387e-11 2.15216733e-08]\n"," ...\n"," [1.53404189e-15 1.70396599e-16 3.91804577e-15 ... 2.86246039e-15\n","  3.23801558e-16 2.59001584e-15]\n"," [1.27121022e-11 9.90096980e-12 8.65826369e-11 ... 4.37883167e-11\n","  6.05044834e-12 6.50171861e-11]\n"," [3.22090504e-15 1.58808479e-14 6.83981053e-15 ... 2.27953473e-14\n","  5.10732788e-15 2.07234864e-13]]\n","(10000, 784)\n"]}]}]}